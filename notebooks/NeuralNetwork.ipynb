{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T15:57:33.674598Z",
     "start_time": "2020-06-04T15:57:30.636304Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import warnings\n",
    "from math import sqrt\n",
    "import scipy.stats as st\n",
    "\n",
    "# Neural Network \n",
    "from numpy import array\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from tensorflow.keras.optimizers import Adam # Custom optimizer\n",
    "\n",
    "\n",
    "from data_preprocess import pre_processing # Used to preprocess data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import make_scorer, f1_score, precision_score, recall_score, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "from data_preprocess import pre_processing # Used to preprocess data\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetworkAccel:\n",
    "    def __init__(self, df, y_label, sequence_matters=False, \n",
    "                 random_state=42, train_size=0.8,\n",
    "                 epochs=100, loss='binary_crossentropy', opt=None, \n",
    "                 validation_split=0.3, drop_out=0.25, \n",
    "                 num_nodes=64, num_hidden_layers=3,\n",
    "                 learning_rate=0.0001, metrics = [keras.metrics.AUC()]\n",
    "                 activation='relu', output_activation='sigmoid',\n",
    "                 kernel_initializer='he_normal', class_weights=None,\n",
    "                 **kwargs):\n",
    "        \"\"\" \n",
    "        params:\n",
    "        df: dataframe which we want to detect the anomaly\n",
    "        y_label: the y label of which we are predicting\n",
    "\n",
    "        \"\"\"   \n",
    "        df.default_ind = df.default_ind.apply(lambda x: int(not x)) # Flip 1 and 0\n",
    "        y = df['default_ind']\n",
    "        X = df.drop('default_ind', axis=1)\n",
    "        \n",
    "        # Train test split\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1-train_size, shuffle=(not sequence_matters), random_state=random_state)\n",
    "        X_train = X_train.copy() # Prevent warnings\n",
    "        X_test = X_test.copy() # Prevent warnings\n",
    "    \n",
    "        # Scale data\n",
    "        scalers = dict() # Save them in dictionary so we can rescale them back\n",
    "        for col in X_train.columns:\n",
    "            if len(X_train[col].unique()) != 2:\n",
    "                scalers[col] = StandardScaler()\n",
    "                scalers[col].fit(X_train[col].values.reshape(-1, 1))\n",
    "                X_train[col] = scalers[col].transform(X_train[col].values.reshape(-1, 1))\n",
    "                X_test[col] = scalers[col].transform(X_test[col].values.reshape(-1, 1))\n",
    "                \n",
    "        self.scalers = scalers\n",
    "        \n",
    "        # Dense Neural Network Model\n",
    "        num_features = len(X_train.columns)\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(num_nodes, input_dim=num_features, activation=activation))\n",
    "        for _ in range(num_hidden_layers - 1):\n",
    "            model.add(Dense(num_nodes, activation=activation, kernel_initializer = \"he_normal\"))\n",
    "            model.add(Dropout(drop_out))\n",
    "        model.add(Dense(num_nodes, activation=activation, kernel_initializer = \"he_normal\"))\n",
    "        model.add(Dense(1, activation=output_activation))\n",
    "        \n",
    "        # Create weights for unbalanced data\n",
    "        if class_weights is None:\n",
    "            class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                             np.unique(y_train),\n",
    "                                                             y_train)\n",
    "        if opt is None:\n",
    "            opt = Adam(lr=learning_rate)\n",
    "        \n",
    "        model.compile(loss=loss, optimizer=opt, metrics=metrics)\n",
    "\n",
    "        history = model.fit(X_train.values, y_train, epochs=epochs, validation_split=validation_split, class_weight=class_weights)\n",
    "        \n",
    "        self.model = model\n",
    "        \n",
    "    def predict(self, data):\n",
    "        \"\"\"\n",
    "        This method predicts anomalies given a dataset that this class was trained on,\n",
    "        the dataset must have the same columns as the trained model, it will output the \n",
    "        an array of anomalies, also returns probabilities for each for ROC_AUC scores\n",
    "        \"\"\"\n",
    "        return self.model.predict(data), self.model.predict_proba(data)[:, 1]\n",
    "    \n",
    "        @staticmethod\n",
    "    def get_scores(y_pred, y_true, scoring='f1', y_proba=None):\n",
    "        if scoring.startswith('f1'):\n",
    "            score = f1_score(y_pred, y_true)\n",
    "        elif scoring.startswith('pre'):\n",
    "            score = precision_score(y_pred, y_true)\n",
    "        elif scoring.startswith('rec'):\n",
    "            score = recall_score(y_pred, y_true)\n",
    "        elif scoring.startswith('acc'):\n",
    "            score = accuracy_score(y_pred, y_true)\n",
    "        elif scoring.startswith('roc'):\n",
    "            if  y_proba is None:\n",
    "                score = 'ROC AUC requires probability scores'\n",
    "            else:\n",
    "                score = roc_auc_score(y_pred, y_proba)\n",
    "        else:\n",
    "            score = f\"Scoring Method: {scoring} not implemented\"\n",
    "        return score\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_all_scores(y_pred, y_true, y_proba):\n",
    "        # This just prints all scores above above\n",
    "        print(f\"ROC_AUC: {LightGBMAccel.get_scores(y_pred, y_true, scoring='roc', y_proba=y_proba):0.2f}\")\n",
    "        print(f\"F1: {LightGBMAccel.get_scores(y_pred, y_true, scoring='f1'):0.2f}\")\n",
    "        print(f\"Precision: {LightGBMAccel.get_scores(y_pred, y_true, scoring='pre'):0.2f}\")\n",
    "        print(f\"Recall: {LightGBMAccel.get_scores(y_pred, y_true, scoring='rec'):0.2f}\")\n",
    "        print(f\"Accuracy: {LightGBMAccel.get_scores(y_pred, y_true, scoring='acc'):0.2f}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def get_confusion_matrix(y_pred, y_true, cmap='coolwarm'):\n",
    "        plt.figure(figsize=(10,8))\n",
    "        \n",
    "        cf_matrix = confusion_matrix(y_test, y_true)\n",
    "        group_names = ['Non-Anomalies', 'Falsely Flagged Anom', 'Unflagged Anom', 'True Anomalies']\n",
    "        group_counts = [\"{0:0.0f}\".format(value) for value in cf_matrix.flatten()]\n",
    "        group_percentages = [\"{0:.2%}\".format(value) for value in cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "        \n",
    "        # Labels combine group names, counts, and percentages\n",
    "        labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names, group_counts, group_percentages)] \n",
    "        labels = np.asarray(labels).reshape(2,2)\n",
    "              \n",
    "        sns.heatmap(cf_matrix, annot=labels, fmt=\"\", cmap=cmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T15:57:33.950111Z",
     "start_time": "2020-06-04T15:57:33.675631Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pre_processing(pd.read_csv(\"data.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T15:57:33.958945Z",
     "start_time": "2020-06-04T15:57:33.951964Z"
    }
   },
   "outputs": [],
   "source": [
    "df.default_ind = df.default_ind.apply(lambda x: int(not x)) # Flip 1 and 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T15:57:33.969950Z",
     "start_time": "2020-06-04T15:57:33.960946Z"
    }
   },
   "outputs": [],
   "source": [
    "y = df['default_ind']\n",
    "X = df.drop('default_ind', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T15:57:33.981910Z",
     "start_time": "2020-06-04T15:57:33.971911Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T15:57:34.017791Z",
     "start_time": "2020-06-04T15:57:33.982881Z"
    }
   },
   "outputs": [],
   "source": [
    "# Additional preprocessing for neural networks\n",
    "\n",
    "# Scale data\n",
    "scalers = dict() # Save them in dictionary so we can rescale them back\n",
    "for col in X_train.columns:\n",
    "    if len(X_train[col].unique()) != 2:\n",
    "        scalers[col] = StandardScaler()\n",
    "        scalers[col].fit(X_train[col].values.reshape(-1, 1))\n",
    "        X_train[col] = scalers[col].transform(X_train[col].values.reshape(-1, 1))\n",
    "        X_test[col] = scalers[col].transform(X_test[col].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T17:13:45.700118Z",
     "start_time": "2020-06-04T17:12:56.390116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 4900 samples, validate on 2100 samples\n",
      "Epoch 1/150\n",
      "4900/4900 [==============================] - 1s 102us/step - loss: 0.4758 - auc_7: 0.4901 - val_loss: 0.4397 - val_auc_7: 0.5715\n",
      "Epoch 2/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.4479 - auc_7: 0.5390 - val_loss: 0.4365 - val_auc_7: 0.6129\n",
      "Epoch 3/150\n",
      "4900/4900 [==============================] - 0s 64us/step - loss: 0.4391 - auc_7: 0.5525 - val_loss: 0.4299 - val_auc_7: 0.6387\n",
      "Epoch 4/150\n",
      "4900/4900 [==============================] - 0s 64us/step - loss: 0.4252 - auc_7: 0.6047 - val_loss: 0.4190 - val_auc_7: 0.6508\n",
      "Epoch 5/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.4250 - auc_7: 0.6063 - val_loss: 0.4217 - val_auc_7: 0.6597\n",
      "Epoch 6/150\n",
      "4900/4900 [==============================] - 0s 64us/step - loss: 0.4202 - auc_7: 0.6266 - val_loss: 0.4214 - val_auc_7: 0.6652\n",
      "Epoch 7/150\n",
      "4900/4900 [==============================] - 0s 63us/step - loss: 0.4157 - auc_7: 0.6436 - val_loss: 0.4179 - val_auc_7: 0.6653\n",
      "Epoch 8/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.4144 - auc_7: 0.6454 - val_loss: 0.4183 - val_auc_7: 0.6691\n",
      "Epoch 9/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.4051 - auc_7: 0.6720 - val_loss: 0.4144 - val_auc_7: 0.6719\n",
      "Epoch 10/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.4071 - auc_7: 0.6676 - val_loss: 0.4144 - val_auc_7: 0.6741\n",
      "Epoch 11/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.4051 - auc_7: 0.6761 - val_loss: 0.4122 - val_auc_7: 0.6772\n",
      "Epoch 12/150\n",
      "4900/4900 [==============================] - 0s 64us/step - loss: 0.3965 - auc_7: 0.6968 - val_loss: 0.4154 - val_auc_7: 0.6785\n",
      "Epoch 13/150\n",
      "4900/4900 [==============================] - 0s 63us/step - loss: 0.3987 - auc_7: 0.6933 - val_loss: 0.4116 - val_auc_7: 0.6804\n",
      "Epoch 14/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.3994 - auc_7: 0.6924 - val_loss: 0.4183 - val_auc_7: 0.6794\n",
      "Epoch 15/150\n",
      "4900/4900 [==============================] - 0s 58us/step - loss: 0.3909 - auc_7: 0.7127 - val_loss: 0.4082 - val_auc_7: 0.6794\n",
      "Epoch 16/150\n",
      "4900/4900 [==============================] - 0s 60us/step - loss: 0.3919 - auc_7: 0.7116 - val_loss: 0.4154 - val_auc_7: 0.6800\n",
      "Epoch 17/150\n",
      "4900/4900 [==============================] - 0s 62us/step - loss: 0.3883 - auc_7: 0.7200 - val_loss: 0.4079 - val_auc_7: 0.6810\n",
      "Epoch 18/150\n",
      "4900/4900 [==============================] - 0s 60us/step - loss: 0.3878 - auc_7: 0.7203 - val_loss: 0.4118 - val_auc_7: 0.6805\n",
      "Epoch 19/150\n",
      "4900/4900 [==============================] - 0s 60us/step - loss: 0.3859 - auc_7: 0.7247 - val_loss: 0.4138 - val_auc_7: 0.6835\n",
      "Epoch 20/150\n",
      "4900/4900 [==============================] - 0s 61us/step - loss: 0.3812 - auc_7: 0.7370 - val_loss: 0.4097 - val_auc_7: 0.6844\n",
      "Epoch 21/150\n",
      "4900/4900 [==============================] - 0s 61us/step - loss: 0.3830 - auc_7: 0.7344 - val_loss: 0.4133 - val_auc_7: 0.6817\n",
      "Epoch 22/150\n",
      "4900/4900 [==============================] - 0s 59us/step - loss: 0.3768 - auc_7: 0.7464 - val_loss: 0.4100 - val_auc_7: 0.6811\n",
      "Epoch 23/150\n",
      "4900/4900 [==============================] - 0s 62us/step - loss: 0.3787 - auc_7: 0.7426 - val_loss: 0.4159 - val_auc_7: 0.6778\n",
      "Epoch 24/150\n",
      "4900/4900 [==============================] - 0s 62us/step - loss: 0.3775 - auc_7: 0.7452 - val_loss: 0.4133 - val_auc_7: 0.6800\n",
      "Epoch 25/150\n",
      "4900/4900 [==============================] - 0s 62us/step - loss: 0.3795 - auc_7: 0.7415 - val_loss: 0.4111 - val_auc_7: 0.6818\n",
      "Epoch 26/150\n",
      "4900/4900 [==============================] - 0s 60us/step - loss: 0.3734 - auc_7: 0.7565 - val_loss: 0.4102 - val_auc_7: 0.6810\n",
      "Epoch 27/150\n",
      "4900/4900 [==============================] - 0s 64us/step - loss: 0.3696 - auc_7: 0.7628 - val_loss: 0.4115 - val_auc_7: 0.6817\n",
      "Epoch 28/150\n",
      "4900/4900 [==============================] - 0s 63us/step - loss: 0.3664 - auc_7: 0.7676 - val_loss: 0.4128 - val_auc_7: 0.6805\n",
      "Epoch 29/150\n",
      "4900/4900 [==============================] - 0s 73us/step - loss: 0.3690 - auc_7: 0.7631 - val_loss: 0.4129 - val_auc_7: 0.6797\n",
      "Epoch 30/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.3656 - auc_7: 0.7705 - val_loss: 0.4164 - val_auc_7: 0.6791\n",
      "Epoch 31/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.3609 - auc_7: 0.7817 - val_loss: 0.4137 - val_auc_7: 0.6783\n",
      "Epoch 32/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.3602 - auc_7: 0.7803 - val_loss: 0.4151 - val_auc_7: 0.6797\n",
      "Epoch 33/150\n",
      "4900/4900 [==============================] - 0s 77us/step - loss: 0.3589 - auc_7: 0.7822 - val_loss: 0.4163 - val_auc_7: 0.6783\n",
      "Epoch 34/150\n",
      "4900/4900 [==============================] - 0s 78us/step - loss: 0.3539 - auc_7: 0.7912 - val_loss: 0.4183 - val_auc_7: 0.6770\n",
      "Epoch 35/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.3526 - auc_7: 0.7942 - val_loss: 0.4222 - val_auc_7: 0.6730\n",
      "Epoch 36/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.3512 - auc_7: 0.7984 - val_loss: 0.4218 - val_auc_7: 0.6738\n",
      "Epoch 37/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.3495 - auc_7: 0.8001 - val_loss: 0.4223 - val_auc_7: 0.6697\n",
      "Epoch 38/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.3393 - auc_7: 0.8155 - val_loss: 0.4306 - val_auc_7: 0.6705\n",
      "Epoch 39/150\n",
      "4900/4900 [==============================] - 0s 69us/step - loss: 0.3395 - auc_7: 0.8155 - val_loss: 0.4291 - val_auc_7: 0.6662\n",
      "Epoch 40/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.3350 - auc_7: 0.8221 - val_loss: 0.4325 - val_auc_7: 0.6668\n",
      "Epoch 41/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.3281 - auc_7: 0.8332 - val_loss: 0.4387 - val_auc_7: 0.6667\n",
      "Epoch 42/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.3276 - auc_7: 0.8332 - val_loss: 0.4402 - val_auc_7: 0.6658\n",
      "Epoch 43/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.3230 - auc_7: 0.8399 - val_loss: 0.4451 - val_auc_7: 0.6555\n",
      "Epoch 44/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.3194 - auc_7: 0.8435 - val_loss: 0.4463 - val_auc_7: 0.6578\n",
      "Epoch 45/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.3187 - auc_7: 0.8444 - val_loss: 0.4456 - val_auc_7: 0.6572\n",
      "Epoch 46/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.3116 - auc_7: 0.8542 - val_loss: 0.4545 - val_auc_7: 0.6554\n",
      "Epoch 47/150\n",
      "4900/4900 [==============================] - 0s 71us/step - loss: 0.3132 - auc_7: 0.8514 - val_loss: 0.4592 - val_auc_7: 0.6522\n",
      "Epoch 48/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.2981 - auc_7: 0.8698 - val_loss: 0.4680 - val_auc_7: 0.6557\n",
      "Epoch 49/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.2984 - auc_7: 0.8676 - val_loss: 0.4687 - val_auc_7: 0.6473\n",
      "Epoch 50/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.2947 - auc_7: 0.8739 - val_loss: 0.4789 - val_auc_7: 0.6491\n",
      "Epoch 51/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.2917 - auc_7: 0.8781 - val_loss: 0.4784 - val_auc_7: 0.6461\n",
      "Epoch 52/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.2839 - auc_7: 0.8845 - val_loss: 0.4890 - val_auc_7: 0.6479\n",
      "Epoch 53/150\n",
      "4900/4900 [==============================] - 0s 64us/step - loss: 0.2815 - auc_7: 0.8860 - val_loss: 0.4934 - val_auc_7: 0.6479\n",
      "Epoch 54/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.2740 - auc_7: 0.8941 - val_loss: 0.4974 - val_auc_7: 0.6489\n",
      "Epoch 55/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.2622 - auc_7: 0.9062 - val_loss: 0.5198 - val_auc_7: 0.6435\n",
      "Epoch 56/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.2625 - auc_7: 0.9037 - val_loss: 0.5264 - val_auc_7: 0.6428\n",
      "Epoch 57/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.2660 - auc_7: 0.8996 - val_loss: 0.5270 - val_auc_7: 0.6333\n",
      "Epoch 58/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.2515 - auc_7: 0.9145 - val_loss: 0.5424 - val_auc_7: 0.6352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.2547 - auc_7: 0.9110 - val_loss: 0.5514 - val_auc_7: 0.6373\n",
      "Epoch 60/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.2529 - auc_7: 0.9130 - val_loss: 0.5505 - val_auc_7: 0.6391\n",
      "Epoch 61/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.2513 - auc_7: 0.9130 - val_loss: 0.5535 - val_auc_7: 0.6314\n",
      "Epoch 62/150\n",
      "4900/4900 [==============================] - 0s 64us/step - loss: 0.2394 - auc_7: 0.9235 - val_loss: 0.5728 - val_auc_7: 0.6309\n",
      "Epoch 63/150\n",
      "4900/4900 [==============================] - 0s 64us/step - loss: 0.2344 - auc_7: 0.9275 - val_loss: 0.5911 - val_auc_7: 0.6336\n",
      "Epoch 64/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.2304 - auc_7: 0.9294 - val_loss: 0.5863 - val_auc_7: 0.6306\n",
      "Epoch 65/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.2289 - auc_7: 0.9307 - val_loss: 0.5976 - val_auc_7: 0.6296\n",
      "Epoch 66/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.2241 - auc_7: 0.9345 - val_loss: 0.6120 - val_auc_7: 0.6261\n",
      "Epoch 67/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.2192 - auc_7: 0.9370 - val_loss: 0.6257 - val_auc_7: 0.6225\n",
      "Epoch 68/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.2136 - auc_7: 0.9403 - val_loss: 0.6303 - val_auc_7: 0.6159\n",
      "Epoch 69/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.2125 - auc_7: 0.9419 - val_loss: 0.6469 - val_auc_7: 0.6198\n",
      "Epoch 70/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.2055 - auc_7: 0.9459 - val_loss: 0.6526 - val_auc_7: 0.6231\n",
      "Epoch 71/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.2079 - auc_7: 0.9442 - val_loss: 0.6602 - val_auc_7: 0.6187\n",
      "Epoch 72/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.1955 - auc_7: 0.9515 - val_loss: 0.6935 - val_auc_7: 0.6158\n",
      "Epoch 73/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.1947 - auc_7: 0.9514 - val_loss: 0.7077 - val_auc_7: 0.6095\n",
      "Epoch 74/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.1936 - auc_7: 0.9528 - val_loss: 0.7025 - val_auc_7: 0.6177\n",
      "Epoch 75/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.1887 - auc_7: 0.9552 - val_loss: 0.7064 - val_auc_7: 0.6141\n",
      "Epoch 76/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.1800 - auc_7: 0.9600 - val_loss: 0.7249 - val_auc_7: 0.6142\n",
      "Epoch 77/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.1773 - auc_7: 0.9600 - val_loss: 0.7369 - val_auc_7: 0.6097\n",
      "Epoch 78/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.1745 - auc_7: 0.9615 - val_loss: 0.7663 - val_auc_7: 0.6088\n",
      "Epoch 79/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.1781 - auc_7: 0.9580 - val_loss: 0.7658 - val_auc_7: 0.6143\n",
      "Epoch 80/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.1708 - auc_7: 0.9632 - val_loss: 0.7828 - val_auc_7: 0.6134\n",
      "Epoch 81/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.1572 - auc_7: 0.9698 - val_loss: 0.8012 - val_auc_7: 0.6085\n",
      "Epoch 82/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.1625 - auc_7: 0.9677 - val_loss: 0.8087 - val_auc_7: 0.6050\n",
      "Epoch 83/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.1519 - auc_7: 0.9717 - val_loss: 0.8443 - val_auc_7: 0.6061\n",
      "Epoch 84/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.1541 - auc_7: 0.9710 - val_loss: 0.8517 - val_auc_7: 0.6075\n",
      "Epoch 85/150\n",
      "4900/4900 [==============================] - 0s 69us/step - loss: 0.1577 - auc_7: 0.9682 - val_loss: 0.8588 - val_auc_7: 0.6087\n",
      "Epoch 86/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.1487 - auc_7: 0.9733 - val_loss: 0.8710 - val_auc_7: 0.6058\n",
      "Epoch 87/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.1384 - auc_7: 0.9770 - val_loss: 0.9136 - val_auc_7: 0.6081\n",
      "Epoch 88/150\n",
      "4900/4900 [==============================] - 0s 70us/step - loss: 0.1459 - auc_7: 0.9729 - val_loss: 0.8989 - val_auc_7: 0.6019\n",
      "Epoch 89/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.1408 - auc_7: 0.9764 - val_loss: 0.9085 - val_auc_7: 0.6059\n",
      "Epoch 90/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.1381 - auc_7: 0.9770 - val_loss: 0.9097 - val_auc_7: 0.6057\n",
      "Epoch 91/150\n",
      "4900/4900 [==============================] - 0s 71us/step - loss: 0.1264 - auc_7: 0.9812 - val_loss: 0.9380 - val_auc_7: 0.6094\n",
      "Epoch 92/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.1326 - auc_7: 0.9784 - val_loss: 0.9589 - val_auc_7: 0.5990\n",
      "Epoch 93/150\n",
      "4900/4900 [==============================] - 0s 69us/step - loss: 0.1212 - auc_7: 0.9817 - val_loss: 1.0032 - val_auc_7: 0.6006\n",
      "Epoch 94/150\n",
      "4900/4900 [==============================] - 0s 70us/step - loss: 0.1239 - auc_7: 0.9812 - val_loss: 1.0154 - val_auc_7: 0.5993\n",
      "Epoch 95/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.1325 - auc_7: 0.9767 - val_loss: 0.9987 - val_auc_7: 0.5998\n",
      "Epoch 96/150\n",
      "4900/4900 [==============================] - 0s 69us/step - loss: 0.1170 - auc_7: 0.9829 - val_loss: 1.0297 - val_auc_7: 0.6043\n",
      "Epoch 97/150\n",
      "4900/4900 [==============================] - 0s 70us/step - loss: 0.1081 - auc_7: 0.9858 - val_loss: 1.0578 - val_auc_7: 0.5971\n",
      "Epoch 98/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.1126 - auc_7: 0.9844 - val_loss: 1.0765 - val_auc_7: 0.5909\n",
      "Epoch 99/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.1105 - auc_7: 0.9850 - val_loss: 1.0646 - val_auc_7: 0.5923\n",
      "Epoch 100/150\n",
      "4900/4900 [==============================] - 0s 69us/step - loss: 0.1109 - auc_7: 0.9853 - val_loss: 1.0677 - val_auc_7: 0.5977\n",
      "Epoch 101/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.1172 - auc_7: 0.9822 - val_loss: 1.0804 - val_auc_7: 0.5976\n",
      "Epoch 102/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.1043 - auc_7: 0.9866 - val_loss: 1.0782 - val_auc_7: 0.5938\n",
      "Epoch 103/150\n",
      "4900/4900 [==============================] - 0s 69us/step - loss: 0.1035 - auc_7: 0.9868 - val_loss: 1.1033 - val_auc_7: 0.5962\n",
      "Epoch 104/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.1047 - auc_7: 0.9851 - val_loss: 1.1122 - val_auc_7: 0.5957\n",
      "Epoch 105/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.0994 - auc_7: 0.9882 - val_loss: 1.1232 - val_auc_7: 0.5942\n",
      "Epoch 106/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.0942 - auc_7: 0.9884 - val_loss: 1.1556 - val_auc_7: 0.5933\n",
      "Epoch 107/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.0967 - auc_7: 0.9884 - val_loss: 1.1753 - val_auc_7: 0.5942\n",
      "Epoch 108/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.0919 - auc_7: 0.9895 - val_loss: 1.1648 - val_auc_7: 0.5891\n",
      "Epoch 109/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.0861 - auc_7: 0.9909 - val_loss: 1.2433 - val_auc_7: 0.5855\n",
      "Epoch 110/150\n",
      "4900/4900 [==============================] - 0s 69us/step - loss: 0.0908 - auc_7: 0.9903 - val_loss: 1.1993 - val_auc_7: 0.5945\n",
      "Epoch 111/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.0871 - auc_7: 0.9899 - val_loss: 1.1992 - val_auc_7: 0.5961\n",
      "Epoch 112/150\n",
      "4900/4900 [==============================] - 0s 71us/step - loss: 0.0856 - auc_7: 0.9903 - val_loss: 1.2430 - val_auc_7: 0.5910\n",
      "Epoch 113/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.0853 - auc_7: 0.9909 - val_loss: 1.2740 - val_auc_7: 0.5868\n",
      "Epoch 114/150\n",
      "4900/4900 [==============================] - 0s 69us/step - loss: 0.0782 - auc_7: 0.9929 - val_loss: 1.3289 - val_auc_7: 0.5832\n",
      "Epoch 115/150\n",
      "4900/4900 [==============================] - 0s 69us/step - loss: 0.0767 - auc_7: 0.9931 - val_loss: 1.3550 - val_auc_7: 0.5731\n",
      "Epoch 116/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.0802 - auc_7: 0.9914 - val_loss: 1.3672 - val_auc_7: 0.5794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.0684 - auc_7: 0.9947 - val_loss: 1.3925 - val_auc_7: 0.5757\n",
      "Epoch 118/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.0739 - auc_7: 0.9933 - val_loss: 1.4088 - val_auc_7: 0.5776\n",
      "Epoch 119/150\n",
      "4900/4900 [==============================] - 0s 62us/step - loss: 0.0699 - auc_7: 0.9932 - val_loss: 1.3788 - val_auc_7: 0.5871\n",
      "Epoch 120/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.0742 - auc_7: 0.9935 - val_loss: 1.4072 - val_auc_7: 0.5820\n",
      "Epoch 121/150\n",
      "4900/4900 [==============================] - 0s 64us/step - loss: 0.0724 - auc_7: 0.9938 - val_loss: 1.4388 - val_auc_7: 0.5765\n",
      "Epoch 122/150\n",
      "4900/4900 [==============================] - 0s 60us/step - loss: 0.0758 - auc_7: 0.9922 - val_loss: 1.3982 - val_auc_7: 0.5827\n",
      "Epoch 123/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.0588 - auc_7: 0.9954 - val_loss: 1.4303 - val_auc_7: 0.5797\n",
      "Epoch 124/150\n",
      "4900/4900 [==============================] - 0s 64us/step - loss: 0.0636 - auc_7: 0.9953 - val_loss: 1.4640 - val_auc_7: 0.5735\n",
      "Epoch 125/150\n",
      "4900/4900 [==============================] - 0s 64us/step - loss: 0.0709 - auc_7: 0.9936 - val_loss: 1.4099 - val_auc_7: 0.5858\n",
      "Epoch 126/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.0697 - auc_7: 0.9932 - val_loss: 1.4371 - val_auc_7: 0.5795\n",
      "Epoch 127/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.0536 - auc_7: 0.9967 - val_loss: 1.4836 - val_auc_7: 0.5776\n",
      "Epoch 128/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.0625 - auc_7: 0.9947 - val_loss: 1.5654 - val_auc_7: 0.5717\n",
      "Epoch 129/150\n",
      "4900/4900 [==============================] - 0s 57us/step - loss: 0.0621 - auc_7: 0.9952 - val_loss: 1.4777 - val_auc_7: 0.5779\n",
      "Epoch 130/150\n",
      "4900/4900 [==============================] - 0s 57us/step - loss: 0.0568 - auc_7: 0.9956 - val_loss: 1.5523 - val_auc_7: 0.5771\n",
      "Epoch 131/150\n",
      "4900/4900 [==============================] - 0s 64us/step - loss: 0.0669 - auc_7: 0.9922 - val_loss: 1.5442 - val_auc_7: 0.5651\n",
      "Epoch 132/150\n",
      "4900/4900 [==============================] - 0s 61us/step - loss: 0.0590 - auc_7: 0.9960 - val_loss: 1.5827 - val_auc_7: 0.5642\n",
      "Epoch 133/150\n",
      "4900/4900 [==============================] - 0s 62us/step - loss: 0.0579 - auc_7: 0.9954 - val_loss: 1.5551 - val_auc_7: 0.5722\n",
      "Epoch 134/150\n",
      "4900/4900 [==============================] - 0s 63us/step - loss: 0.0524 - auc_7: 0.9961 - val_loss: 1.5894 - val_auc_7: 0.5822\n",
      "Epoch 135/150\n",
      "4900/4900 [==============================] - 0s 65us/step - loss: 0.0598 - auc_7: 0.9934 - val_loss: 1.6574 - val_auc_7: 0.5616\n",
      "Epoch 136/150\n",
      "4900/4900 [==============================] - 0s 60us/step - loss: 0.0533 - auc_7: 0.9967 - val_loss: 1.6924 - val_auc_7: 0.5617\n",
      "Epoch 137/150\n",
      "4900/4900 [==============================] - 0s 62us/step - loss: 0.0543 - auc_7: 0.9966 - val_loss: 1.5554 - val_auc_7: 0.5685\n",
      "Epoch 138/150\n",
      "4900/4900 [==============================] - 0s 58us/step - loss: 0.0559 - auc_7: 0.9957 - val_loss: 1.5928 - val_auc_7: 0.5676\n",
      "Epoch 139/150\n",
      "4900/4900 [==============================] - 0s 60us/step - loss: 0.0570 - auc_7: 0.9956 - val_loss: 1.6602 - val_auc_7: 0.5553\n",
      "Epoch 140/150\n",
      "4900/4900 [==============================] - 0s 66us/step - loss: 0.0500 - auc_7: 0.9964 - val_loss: 1.6161 - val_auc_7: 0.5736\n",
      "Epoch 141/150\n",
      "4900/4900 [==============================] - 0s 61us/step - loss: 0.0540 - auc_7: 0.9966 - val_loss: 1.6177 - val_auc_7: 0.5773\n",
      "Epoch 142/150\n",
      "4900/4900 [==============================] - 0s 60us/step - loss: 0.0522 - auc_7: 0.9969 - val_loss: 1.6398 - val_auc_7: 0.5796\n",
      "Epoch 143/150\n",
      "4900/4900 [==============================] - 0s 62us/step - loss: 0.0501 - auc_7: 0.9970 - val_loss: 1.7470 - val_auc_7: 0.5606\n",
      "Epoch 144/150\n",
      "4900/4900 [==============================] - 0s 62us/step - loss: 0.0454 - auc_7: 0.9971 - val_loss: 1.7041 - val_auc_7: 0.5683\n",
      "Epoch 145/150\n",
      "4900/4900 [==============================] - 0s 60us/step - loss: 0.0453 - auc_7: 0.9964 - val_loss: 1.6803 - val_auc_7: 0.5630\n",
      "Epoch 146/150\n",
      "4900/4900 [==============================] - 0s 61us/step - loss: 0.0458 - auc_7: 0.9969 - val_loss: 1.7474 - val_auc_7: 0.5623\n",
      "Epoch 147/150\n",
      "4900/4900 [==============================] - 0s 67us/step - loss: 0.0527 - auc_7: 0.9955 - val_loss: 1.7268 - val_auc_7: 0.5673\n",
      "Epoch 148/150\n",
      "4900/4900 [==============================] - 0s 59us/step - loss: 0.0461 - auc_7: 0.9974 - val_loss: 1.7560 - val_auc_7: 0.5613\n",
      "Epoch 149/150\n",
      "4900/4900 [==============================] - 0s 60us/step - loss: 0.0472 - auc_7: 0.9963 - val_loss: 1.7695 - val_auc_7: 0.5569\n",
      "Epoch 150/150\n",
      "4900/4900 [==============================] - 0s 68us/step - loss: 0.0456 - auc_7: 0.9975 - val_loss: 1.7890 - val_auc_7: 0.5501\n"
     ]
    }
   ],
   "source": [
    "num_features = len(X_train.columns)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(128, input_dim=num_features, activation='relu'))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer = \"he_normal\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer = \"he_normal\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer = \"he_normal\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(128, activation='relu', kernel_initializer = \"he_normal\"))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)\n",
    "opt = Adam(lr=0.0001)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[keras.metrics.AUC()])\n",
    "\n",
    "history = model.fit(X_train.values, y_train, epochs=150, validation_split=0.3, class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:42:13.057802Z",
     "start_time": "2020-06-04T16:42:12.975387Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:42:13.065777Z",
     "start_time": "2020-06-04T16:42:13.058795Z"
    }
   },
   "outputs": [],
   "source": [
    "y_pred = [0 if x < 0.5 else 1 for x in pred ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T19:36:52.518848Z",
     "start_time": "2020-06-04T19:36:52.511899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9867319 ],\n",
       "       [0.9999631 ],\n",
       "       [0.7871119 ],\n",
       "       ...,\n",
       "       [0.9999994 ],\n",
       "       [0.99998283],\n",
       "       [1.        ]], dtype=float32)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-04T16:42:13.073781Z",
     "start_time": "2020-06-04T16:42:13.066773Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  79,  369],\n",
       "       [ 225, 2327]], dtype=int64)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
